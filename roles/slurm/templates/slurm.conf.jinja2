
ClusterName={{ cluster_name }}
SlurmctldHost={{ slurmctld_primary }}

MpiDefault=none
#Epilog=/etc/slurm/epilog.sh
ProctrackType=proctrack/cgroup

ReturnToService=1
SlurmctldPidFile=/var/run/slurmctld.pid
SlurmctldPort=6817
SlurmdPidFile=/var/run/slurmd.pid
SlurmdPort=6818
SlurmdSpoolDir=/var/spool/slurmd
SlurmUser=slurm
AuthAltTypes=auth/jwt
AuthAltParameters=jwt_key=/etc/slurm/jwt_hs256.key

StateSaveLocation=/etc/slurm/state
SwitchType=switch/none
TaskPlugin=task/cgroup,task/affinity

InactiveLimit=0
KillWait=30
MinJobAge=300
SlurmctldTimeout=120
SlurmdTimeout=300

# SCHEDULING
MaxMemPerCPU=1024
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_Socket_Memory # needed for memory limit enforcement in cgroup

# Preemption
PreemptType=preempt/partition_prio
PreemptMode=requeue
JobRequeue=1

# Other
#ResvProlog=/root/resv_prolog.sh
#ResvEpilog=/root/resv_epilog.sh
#CliFilterPlugins=cli_filter/lua


# LOGGING AND ACCOUNTING
AccountingStorageEnforce=qos,limits
AccountingStorageHost={{ slurmctld_primary }}
AccountingStorageType=accounting_storage/slurmdbd
#AccountingStorageTRES=license/testlic1
JobCompType=jobcomp/none
JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/cgroup
SlurmctldDebug=info
SlurmctldLogFile=/etc/slurm/logs/slurmctld.log
SlurmdDebug=info
SlurmdLogFile=/etc/slurm/logs/slurmd.%n.log


#JobSubmitPlugins=lua

EnforcePartLimits=ANY


AuthType=auth/munge

{% for node in slurm_nodes %}
NodeName={{ node.name }} CPUs={{ node.cpus }} Boards=1 SocketsPerBoard={{ node.sockets }} CoresPerSocket={{ node.cpus_per_socket }} ThreadsPerCore=1 RealMemory={{ node.real_memory }}
{% endfor %}

PartitionName=DEFAULT State=UP
PartitionName=DEFAULT MaxTime=1-00
PartitionName=DEFAULT OverSubscribe=NO
PartitionName=DEFAULT PreemptMode=OFF
PartitionName=DEFAULT MaxMemPerCPU=300

PartitionName=all nodes={{ all_computes }}